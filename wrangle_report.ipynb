{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report #weratedogs\n",
    "## Introduction\n",
    "---\n",
    "This report describes the wrangling proces that led to the act_report. The main data source is twitter-archive-enhanced.csv file which is a comma sepparated file created by Weratedogs for Udacity. Weratedogs created this file by downloading their twitter archive containing basic tweet data for all 5000+ of their tweets as they stood on August 1, 2017.\n",
    "The data wrangling process consists of\n",
    "* Data gathering\n",
    "* Assessing data\n",
    "* cleaning data\n",
    "Naturally this is an itterative process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data gathering\n",
    "---\n",
    "Data was gathered from three places as described below.\n",
    "* WeRateDogs Twitter archive. This archive contains basic tweet data for all 5000+ of their tweets.\n",
    "* Twitter api. We use the Twitter api to extract some extra data not present in the archive.\n",
    "* Tweet image prediction. Udacity used a neural network able to classify breeds of dogs to classify the images from weratedogs archive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering data from the Weratedogs Twitter archive\n",
    "WeRateDogs downloaded their Twitter archive and sent it to Udacity via email. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017. This archive was downloaded manually from the following link [twitter-archive-enhanced.csv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv). This file was read into a dataframe (df_archive) using panda's read_csv function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet image predictions\n",
    "The tweet image predictions, what breed of dog is present in each tweet according to a neural network is saved in a tab separated file (image_predictions.tsv). This file is hosted on Udacity's servers at the following url: [image_predictions.tsv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv). This file was downloaded programmatically using the Requests library. Finnally the file was read into a dataframe (df_image_predictions) using panda's read_csv function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API\n",
    "Extra information was received from the Twitter API using the tweepy library. In order to use this library I had to install it first on my system. For this I used conda.\n",
    "```\n",
    "conda install -c conda-forge tweepy\n",
    "```\n",
    "To retrieve data from the Twitter API I needed the Tweet id's. This list was retrived from the weratedogs archive and from the tweet image prediction. Naturally duplicates were removed.\n",
    "The results were saved into another dataframe.\n",
    "Finally the data was saved to the 'tweet_json.txt' file using panda's to_csv function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
